{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13258362,"sourceType":"datasetVersion","datasetId":8401506},{"sourceId":13262864,"sourceType":"datasetVersion","datasetId":8404612},{"sourceId":13341397,"sourceType":"datasetVersion","datasetId":8460285},{"sourceId":13372445,"sourceType":"datasetVersion","datasetId":8483719},{"sourceId":13377570,"sourceType":"datasetVersion","datasetId":8487338}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T17:10:14.602720Z","iopub.execute_input":"2025-10-14T17:10:14.603656Z","iopub.status.idle":"2025-10-14T17:11:37.908206Z","shell.execute_reply.started":"2025-10-14T17:10:14.603629Z","shell.execute_reply":"2025-10-14T17:11:37.907314Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\nimport yaml\nimport os\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom collections import defaultdict\nimport torch\n\n# Define Kaggle paths  \nkaggle_input_dir = \"/kaggle/input/document-dataset-for-yolo/document-dataset-for-yolo\"\n#kaggle_input_dir =\"/kaggle/input/mini-document-dataset-for-yolo/mini-document-dataset-for-yolo\"\n\nkaggle_working_dir = \"/kaggle/working\"\nos.makedirs(kaggle_working_dir, exist_ok=True)\n\n# Check available GPUs and print info\nprint(f\"Available GPUs: {torch.cuda.device_count()}\")\nif torch.cuda.device_count() > 0:\n    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n\n# Path to existing yaml file\nyaml_path = os.path.join(kaggle_input_dir, \"dataset.yaml\")\n\n# Check if YAML file exists\nif not os.path.exists(yaml_path):\n    print(f\"Error: YAML file not found at {yaml_path}\")\nelse:\n    # Load the existing YAML to display info\n    with open(yaml_path, 'r') as f:\n        config = yaml.safe_load(f)\n    print(f\"Using existing YAML config at {yaml_path}\")\n    print(f\"Dataset classes: {config.get('names', {})}\")\n    print(f\"Train path: {config.get('train', '')}\")\n    print(f\"Val path: {config.get('val', '')}\")\n\n# Initialize model - using YOLOv11m for better performance\nmodel = YOLO('yolo11s.pt')\n\n# Training parameters for single GPU\ntraining_params = {\n    # Training parameters\n    \"epochs\": 30, \n    \"imgsz\": 1024,\n    \"batch\": 8,     # Reduced for single GPU\n    \"patience\": 15,\n    \"save\": True,\n    \"device\": 0,    # Use single GPU\n    \"workers\": 4,   # Reduced for single GPU\n    \"optimizer\": \"SGD\",\n    \"verbose\": True,\n    \"seed\": 42,\n    \"deterministic\": True,\n    \"single_cls\": False,  # Multiple classes for documents\n    \"rect\": False,\n    \"cos_lr\": True,\n    \"close_mosaic\": 10,\n    \"resume\": False,\n    \"amp\": True,     # Automatic Mixed Precision\n    \"fraction\": 1.0,\n    \"exist_ok\": True,\n    \"pretrained\": True,\n    \"plots\": True,\n    \"name\": \"document_detector_single_gpu\",\n    \n    # Hyperparameters\n    \"lr0\": 0.01,\n    \"lrf\": 0.01,\n    \"momentum\": 0.937,\n    \"weight_decay\": 0.0005,\n    \"warmup_epochs\": 3.0,\n    \"warmup_momentum\": 0.8,\n    \"warmup_bias_lr\": 0.1,\n    \"box\": 7.5,      # Box loss gain (default)\n    \"cls\": 0.5,      # Class loss gain (default)\n    \"dfl\": 1.5,\n    \n    \"hsv_h\": 0.015,  # Hue variation (very slight - documents are mostly B&W)\n    \"hsv_s\": 0.3,    # Saturation variation (moderate - for scanned documents)\n    \"hsv_v\": 0.3,    # Value/brightness variation (moderate - lighting conditions)\n    \n    # GEOMETRIC AUGMENTATIONS - CONSERVATIVE (preserve text readability)\n    \"degrees\": 5.0,      # Small rotation (±5°) - realistic for slight page tilt\n    \"translate\": 0.05,   # Small translation (5%) - document position variation\n    \"scale\": 0.15,       # Moderate scaling (±15%) - distance from camera/scanner\n    \"shear\": 2.0,        # Minimal shear (2°) - perspective distortion\n    \"perspective\": 0.0001, # Very minimal perspective - almost flat documents\n    \n    # FLIP AUGMENTATIONS - STRATEGIC\n    \"flipud\": 0.0,       # NO vertical flip (text would be upside down)\n    \"fliplr\": 0.0,       # NO horizontal flip (equations have directionality)\n    \n    # ADVANCED AUGMENTATIONS - DISABLED (can distort text/equations)\n    \"mosaic\": 0.0,       # NO mosaic (would break document structure)\n    \"mixup\": 0.0,        # NO mixup (would blend different documents)\n    \"copy_paste\": 0.0,   # NO copy-paste (can create unrealistic layouts)\n    \n    # ADDITIONAL RECOMMENDED SETTINGS\n    \"dropout\": 0.0,      # No dropout augmentation\n    \"auto_augment\": None,\n}\n\nprint(\"Starting training on single GPU...\")\nprint(f\"Training parameters: {training_params}\")\n\n# Train the model directly using the original YAML\nresults = model.train(\n    data=yaml_path,\n    **training_params\n)\n# Save the trained model to Kaggle working directory\nmodel_save_path = os.path.join(kaggle_working_dir, \"document_detection_model.pt\")\nmodel.save(model_save_path)\nprint(f\"Model saved to Kaggle working directory: {model_save_path}\")\n\n# Also export to ONNX format\ntry:\n    onnx_save_path = os.path.join(kaggle_working_dir, \"document_detection_model.onnx\") \n    model.export(format=\"onnx\", imgsz=1024)\n    print(f\"Model exported to ONNX format at: {onnx_save_path}\")\nexcept Exception as e:\n    print(f\"ONNX export failed: {e}\")\n\n# Safely save training history if available\ntry:\n    # First, check if the results object has the results_dict attribute\n    if hasattr(results, 'results_dict') and results.results_dict:\n        # Try to convert to DataFrame with explicit index\n        if isinstance(results.results_dict, dict):\n            # If it's a dictionary of epoch data\n            history_df = pd.DataFrame.from_dict(results.results_dict, orient='index')\n            history_path = os.path.join(kaggle_working_dir, \"training_history.csv\")\n            history_df.to_csv(history_path)\n            print(f\"Training history saved to: {history_path}\")\n        else:\n            # If it's a list or another format\n            history_df = pd.DataFrame(results.results_dict, index=range(len(results.results_dict)))\n            history_path = os.path.join(kaggle_working_dir, \"training_history.csv\")\n            history_df.to_csv(history_path, index=False)\n            print(f\"Training history saved to: {history_path}\")\n    else:\n        print(\"No results dictionary found in training results. Looking for CSV file...\")\n        \n    # Try to find the CSV file that YOLO automatically creates\n    runs_dir = os.path.join(kaggle_working_dir, \"runs\", \"detect\", \"document_detector_single_gpu\")\n    results_csv_path = os.path.join(runs_dir, \"results.csv\")\n    \n    if os.path.exists(results_csv_path):\n        print(f\"Found training history at: {results_csv_path}\")\n        history_df = pd.read_csv(results_csv_path)\n        history_path = os.path.join(kaggle_working_dir, \"training_history.csv\")\n        history_df.to_csv(history_path, index=False)\n        print(f\"Training history copied to: {history_path}\")\nexcept Exception as e:\n    print(f\"Error saving training history: {str(e)}\")\n    print(\"Continuing with validation...\")\n\n# Validate the model\nval_results = model.val(\n    data=yaml_path,\n    imgsz=1024,\n    batch=8,\n    device=0,\n    plots=True\n)\n\nprint(f\"Validation results:\")\nprint(f\"  mAP@0.5 = {val_results.box.map50:.4f}\")\nprint(f\"  mAP@0.5:0.95 = {val_results.box.map:.4f}\")\nprint(f\"  Precision = {val_results.box.mp:.4f}\")\nprint(f\"  Recall = {val_results.box.mr:.4f}\")\n\n# Save validation metrics\nmetrics = {\n    \"mAP50\": val_results.box.map50,\n    \"mAP50-95\": val_results.box.map,\n    \"precision\": val_results.box.mp,\n    \"recall\": val_results.box.mr,\n    \"maps\":val_results.box.maps\n}\nmetrics_df = pd.DataFrame([metrics])\nmetrics_path = os.path.join(kaggle_working_dir, \"validation_metrics.csv\")\nmetrics_df.to_csv(metrics_path, index=False)\nprint(f\"Validation metrics saved to: {metrics_path}\")\n\n# Get class-wise metrics\nclass_names = list(config.get('names', {}).values()) if isinstance(config.get('names'), dict) else config.get('names', [])\nif len(class_names) > 0:\n    print(\"\\nClass-wise metrics:\")\n    for i, class_name in enumerate(class_names):\n        if hasattr(val_results.box, 'maps') and i < len(val_results.box.maps):\n            print(f\"  {class_name}: mAP50 = {val_results.box.maps[i]:.4f}\")\n\n\n# Add this code after your validation section (after line 197)\n\n# Get class-wise and overall metrics\nprint(\"\\n\" + \"=\"*60)\nprint(\"COMPREHENSIVE VALIDATION METRICS\")\nprint(\"=\"*60)\n\n# Overall metrics\noverall_precision = val_results.box.mp\noverall_recall = val_results.box.mr\noverall_f1 = 2 * (overall_precision * overall_recall) / (overall_precision + overall_recall + 1e-6)\n\nprint(\"\\n--- OVERALL METRICS ---\")\nprint(f\"Precision: {overall_precision:.4f}\")\nprint(f\"Recall: {overall_recall:.4f}\")\nprint(f\"F1-Score: {overall_f1:.4f}\")\nprint(f\"mAP@0.5: {val_results.box.map50:.4f}\")\nprint(f\"mAP@0.5:0.95: {val_results.box.map:.4f}\")\n\n# Class-wise metrics\nprint(\"\\n--- CLASS-WISE METRICS ---\")\n\nclass_metrics_list = []\n\n# Check if per-class metrics are available\nif hasattr(val_results.box, 'ap_class_index'):\n    ap_class_index = val_results.box.ap_class_index  # Classes that were found in validation\n    \n    # Get per-class precision and recall\n    if hasattr(val_results.box, 'p') and hasattr(val_results.box, 'r'):\n        precision_per_class = val_results.box.p  # Precision per class\n        recall_per_class = val_results.box.r      # Recall per class\n    else:\n        # Fallback if p and r attributes don't exist\n        precision_per_class = [overall_precision] * len(ap_class_index)\n        recall_per_class = [overall_recall] * len(ap_class_index)\n    \n    # Get mAP per class\n    maps = val_results.box.maps  # mAP@0.5 per class\n    \n    # Get mAP@0.5:0.95 per class if available\n    if hasattr(val_results.box, 'ap') and val_results.box.ap is not None:\n        ap = val_results.box.ap\n        if len(ap.shape) > 1:\n            map50_95_per_class = ap.mean(axis=1)  # Average across IoU thresholds\n        else:\n            map50_95_per_class = ap\n    else:\n        map50_95_per_class = [0] * len(ap_class_index)\n    \n    # Print and collect metrics for each class\n    for i, cls_idx in enumerate(ap_class_index):\n        cls_name = class_names[cls_idx] if cls_idx < len(class_names) else f\"Class {cls_idx}\"\n        \n        prec = float(precision_per_class[i]) if i < len(precision_per_class) else 0.0\n        rec = float(recall_per_class[i]) if i < len(recall_per_class) else 0.0\n        f1 = 2 * (prec * rec) / (prec + rec) if (prec + rec) > 0 else 0.0\n        map50 = float(maps[i]) if i < len(maps) else 0.0\n        map50_95 = float(map50_95_per_class[i]) if i < len(map50_95_per_class) else 0.0\n        \n        print(f\"\\n{cls_name}:\")\n        print(f\"  Precision:    {prec:.4f}\")\n        print(f\"  Recall:       {rec:.4f}\")\n        print(f\"  F1-Score:     {f1:.4f}\")\n        print(f\"  mAP@0.5:      {map50:.4f}\")\n        print(f\"  mAP@0.5:0.95: {map50_95:.4f}\")\n        \n        class_metrics_list.append({\n            'class_id': int(cls_idx),\n            'class_name': cls_name,\n            'precision': prec,\n            'recall': rec,\n            'f1_score': f1,\n            'mAP50': map50,\n            'mAP50-95': map50_95\n        })\nelse:\n    print(\"Per-class metrics not available in validation results\")\n\n# Save detailed metrics to CSV\nif class_metrics_list:\n    # Create DataFrame with both overall and class-wise metrics\n    overall_row = {\n        'class_id': -1,\n        'class_name': 'OVERALL',\n        'precision': overall_precision,\n        'recall': overall_recall,\n        'f1_score': overall_f1,\n        'mAP50': val_results.box.map50,\n        'mAP50-95': val_results.box.map\n    }\n    \n    all_metrics = [overall_row] + class_metrics_list\n    metrics_df = pd.DataFrame(all_metrics)\n    \n    detailed_metrics_path = os.path.join(kaggle_working_dir, \"detailed_class_metrics.csv\")\n    metrics_df.to_csv(detailed_metrics_path, index=False)\n    print(f\"\\nDetailed metrics saved to: {detailed_metrics_path}\")\n    \n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T17:28:23.315872Z","iopub.execute_input":"2025-10-14T17:28:23.316218Z","iopub.status.idle":"2025-10-14T17:28:58.444973Z","shell.execute_reply.started":"2025-10-14T17:28:23.316186Z","shell.execute_reply":"2025-10-14T17:28:58.444027Z"}},"outputs":[],"execution_count":null}]}